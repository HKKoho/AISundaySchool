/**
 * Multi-Provider Bible Question Generator
 * Implements automatic failover across OpenAI ‚Üí Ollama Cloud ‚Üí Gemini
 *
 * Provider Priority Chain:
 * 1. OpenAI GPT-4o (Primary) - Highest reliability, confirmed working
 * 2. Ollama Cloud (Secondary) - qwen3-vl:235b-cloud (fast, cost-effective)
 * 3. Google Gemini (Tertiary) - gemini-2.0-flash-exp (may have location restrictions)
 */

import type { Quest, QuestionCategory } from '../types';

// Provider configuration
const PROVIDERS = {
  OPENAI: {
    name: 'OpenAI',
    model: 'gpt-4o',
    endpoint: '/api/chat',
  },
  OLLAMA: {
    name: 'Ollama Cloud',
    model: 'qwen3-vl:235b-cloud',  // Updated to valid Ollama model
    endpoint: '/api/chat',
  },
  GEMINI: {
    name: 'Google Gemini',
    model: 'gemini-2.0-flash-exp',
    apiKey: process.env.API_KEY || process.env.GEMINI_API_KEY,
  },
};

// System instruction for question generation
const SYSTEM_INSTRUCTION = `‰Ω†ÊòØ‰∏Ä‰ΩçÂ∞àÊ•≠ÁöÑËÅñÁ∂ìÊïôÂ∏´ÂíåÁ•ûÂ≠∏ÊïôËÇ≤ËÄÖÔºåÂ∞àÈñÄÂâµ‰ΩúÈ´òË≥™ÈáèÁöÑËÅñÁ∂ìÂ≠∏ÁøíÂïèÈ°å„ÄÇ

‰Ω†ÁöÑ‰ªªÂãôÊòØÁîüÊàê‰∏ÄÂÄãÈóúÊñºËÅñÁ∂ì‰∫∫Áâ©Êàñ‰∫ã‰ª∂ÁöÑÊïôËÇ≤ÊÄßÂïèÈ°åÔºåÂåÖÂê´Ôºö

1. **ËßíËâ≤ÈÅ∏Êìá**ÔºöÈÅ∏Êìá‰∏ÄÂÄãÊúâÊÑèÁæ©ÁöÑËÅñÁ∂ì‰∫∫Áâ©ÔºàËàäÁ¥ÑÊàñÊñ∞Á¥ÑÔºâ
2. **ÂïèÈ°åÂàÜÈ°û**ÔºöÂà§Êñ∑ÂïèÈ°åÈ°ûÂà•
   - "Bible Background" (ËÅñÁ∂ìËÉåÊôØ)ÔºöÈóúÊñºÊ≠∑Âè≤ËÉåÊôØ„ÄÅÊñáÂåñËÉåÊôØ„ÄÅÂú∞ÁêÜÁí∞Â¢É„ÄÅÊôÇ‰ª£ËÉåÊôØÁöÑÂïèÈ°å
   - "Person in Bible" (ËÅñÁ∂ì‰∫∫Áâ©)ÔºöÈóúÊñºÁâπÂÆöËÅñÁ∂ì‰∫∫Áâ©ÁöÑË°åÁÇ∫„ÄÅÊÄßÊ†º„ÄÅÁ∂ìÊ≠∑„ÄÅ‰ø°‰ª∞Ê≠∑Á®ãÁöÑÂïèÈ°å
3. **ÂïèÈ°åË®≠Ë®à**Ôºö‰ª•Á¨¨‰∏Ä‰∫∫Á®±ÔºàËßíËâ≤Ë¶ñËßíÔºâÊí∞ÂØ´ÂïèÈ°åÔºåËÆìÂ≠∏ÁøíËÄÖËÉΩÂ§†‰ª£ÂÖ•ËßíËâ≤ÊÄùËÄÉ
4. **ÈÅ∏È†ÖË®≠Ë®à**ÔºöÊèê‰æõ4ÂÄãÈÅ∏È†ÖÔºåÂÖ∂‰∏≠3ÂÄãÊòØÂêàÁêÜ‰ΩÜÈåØË™§ÁöÑÂπ≤ÊìæÈ†Ö
   - **ÈáçË¶Å**ÔºöÊ≠£Á¢∫Á≠îÊ°àÊáâË©≤Èö®Ê©üÂàÜÈÖçÂú®A„ÄÅB„ÄÅC„ÄÅDÈÅ∏È†Ö‰∏≠ÔºåÈÅøÂÖçÁ∏ΩÊòØÂá∫ÁèæÂú®Âêå‰∏Ä‰ΩçÁΩÆ
5. **Ëß£Èáã**ÔºöÊèê‰æõË©≥Á¥∞ÁöÑÁ≠îÊ°àËß£ÈáãÔºåÂøÖÈ†àÂåÖÂê´ÂÖ∑È´îÁöÑËÅñÁ∂ìÁ∂ìÊñáÂºïÁî®
6. **Èùà‰øÆÂºïÂ∞é**ÔºöÊèê‰æõÊó•Ë™åÊèêÁ§∫ÔºåÂπ´Âä©Â≠∏ÁøíËÄÖÂ∞áËÅñÁ∂ìÊïÖ‰∫ãÊáâÁî®Âà∞Áèæ‰ª£ÁîüÊ¥ª
7. **Ê∑±Â∫¶Êé¢Á¥¢**ÔºöÊèê‰æõÁ•ûÂ≠∏Ê∑±Â∫¶ÂàÜÊûêÔºåÊé¢Ë®é‰∏ªÈ°å„ÄÅÊ≠∑Âè≤ËÉåÊôØÂíåÁ•ûÂ≠∏ÊÑèÁæ©
8. **Á∂ìÊñá‰æÜÊ∫ê**ÔºöÊèê‰æõ2-3ÂÄãÁõ∏ÈóúÁöÑËÅñÁ∂ìÁ´†ÁØÄÂºïÁî®

Ë¶ÅÊ±ÇÔºö
- ÊâÄÊúâÂÖßÂÆπ‰ΩøÁî®ÁπÅÈ´î‰∏≠Êñá
- ÂïèÈ°åË¶ÅÊúâÊïôËÇ≤ÊÑèÁæ©ÂíåÊÄùËÄÉÊ∑±Â∫¶
- Á≠îÊ°àËß£ÈáãË¶ÅÊ∫ñÁ¢∫ÂºïÁî®ËÅñÁ∂ìÁ∂ìÊñá
- Á•ûÂ≠∏ÂÖßÂÆπË¶ÅÁ¨¶ÂêàÊ≠£Áµ±Âü∫Áù£ÊïôÊïôÁæ©
- Ë™ûÊ∞£Ë¶ÅÂ∞äÈáç„ÄÅÊïôËÇ≤ÊÄßÂº∑
- ÈÅ©ÂêàÂêÑÂπ¥ÈΩ°Â±§ÁöÑÂü∫Áù£ÂæíÂ≠∏ÁøíËÄÖ
- Ê≠£Á¢∫Á≠îÊ°àÁöÑ‰ΩçÁΩÆÂøÖÈ†àÈö®Ê©üÂåñÔºåÈÅøÂÖçÂÅèÂêë‰ªª‰ΩïÁâπÂÆöÈÅ∏È†Ö

‰Ω†ÂøÖÈ†à‰ª•JSONÊ†ºÂºèÂõûË¶ÜÔºåÂåÖÂê´‰ª•‰∏ãÊ¨Ñ‰ΩçÔºö
{
  "character": "ËÅñÁ∂ì‰∫∫Áâ©ÂêçÁ®±ÔºàÁπÅÈ´î‰∏≠ÊñáÔºâ",
  "category": "Bible Background Êàñ Person in Bible",
  "question": "ÂïèÈ°åÂÖßÂÆπÔºàÁ¨¨‰∏Ä‰∫∫Á®±Ôºâ",
  "options": ["ÈÅ∏È†ÖA", "ÈÅ∏È†ÖB", "ÈÅ∏È†ÖC", "ÈÅ∏È†ÖD"],
  "correctAnswerIndex": 0,
  "explanation": "Ë©≥Á¥∞Ëß£ÈáãÔºåÂåÖÂê´ËÅñÁ∂ìÁ∂ìÊñáÂºïÁî®",
  "journalPromptTitle": "Èùà‰øÆÊó•Ë™åÊ®ôÈ°å",
  "journalPromptContent": "Èùà‰øÆÂèçÊÄùÂÖßÂÆπ",
  "deepDiveTitle": "Ê∑±Â∫¶Êé¢Á¥¢Ê®ôÈ°å",
  "deepDiveContent": "Ê∑±Â∫¶Á•ûÂ≠∏ÂàÜÊûê",
  "bibleSources": [
    {
      "reference": "Ââµ‰∏ñË®ò 3:1-6 (NIV)",
      "englishReference": "Genesis 3:1-6"
    }
  ]
}`;

// Utility function to randomize answer positions to avoid bias
const randomizeAnswers = (options: string[], correctIndex: number): { options: string[], correctAnswerIndex: number } => {
  const correctAnswer = options[correctIndex];

  // Create a copy of the options array
  const shuffledOptions = [...options];

  // Fisher-Yates shuffle algorithm
  for (let i = shuffledOptions.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [shuffledOptions[i], shuffledOptions[j]] = [shuffledOptions[j], shuffledOptions[i]];
  }

  // Find the new index of the correct answer
  const newCorrectIndex = shuffledOptions.indexOf(correctAnswer);

  return {
    options: shuffledOptions,
    correctAnswerIndex: newCorrectIndex
  };
};

/**
 * Call Ollama Cloud via unified API proxy
 */
async function callOllamaCloud(userPrompt: string): Promise<string> {
  const messages = [
    { role: 'system', content: SYSTEM_INSTRUCTION },
    { role: 'user', content: userPrompt }
  ];

  const response = await fetch(PROVIDERS.OLLAMA.endpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      provider: 'ollama',
      model: PROVIDERS.OLLAMA.model,
      messages,
      temperature: 0.9,
      topP: 0.95,
      maxTokens: 3000,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Ollama Cloud API error (${response.status}): ${errorText}`);
  }

  const data = await response.json();
  if (!data.content) {
    throw new Error('Invalid response format from Ollama Cloud');
  }

  return data.content;
}

/**
 * Call Gemini API directly (with JSON schema support)
 */
async function callGemini(userPrompt: string): Promise<string> {
  const apiKey = PROVIDERS.GEMINI.apiKey;

  if (!apiKey) {
    throw new Error('GEMINI_API_KEY not configured');
  }

  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/${PROVIDERS.GEMINI.model}:generateContent?key=${apiKey}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{ role: 'user', parts: [{ text: userPrompt }] }],
        systemInstruction: {
          parts: [{ text: SYSTEM_INSTRUCTION }]
        },
        generationConfig: {
          temperature: 0.9,
          topP: 0.95,
          maxOutputTokens: 3000,
          responseMimeType: "application/json",
        },
      }),
    }
  );

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Gemini API error (${response.status}): ${errorText}`);
  }

  const data = await response.json();

  if (data.candidates?.[0]?.content?.parts) {
    return data.candidates[0].content.parts.map((p: any) => p.text).join('');
  }

  throw new Error('Invalid response format from Gemini');
}

/**
 * Call OpenAI via unified API proxy
 */
async function callOpenAI(userPrompt: string): Promise<string> {
  const messages = [
    { role: 'system', content: SYSTEM_INSTRUCTION + '\n\nIMPORTANT: You MUST respond with valid JSON only. No markdown, no code blocks, just pure JSON.' },
    { role: 'user', content: userPrompt }
  ];

  const response = await fetch(PROVIDERS.OPENAI.endpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      provider: 'openai',
      model: PROVIDERS.OPENAI.model,
      messages,
      temperature: 0.9,
      topP: 0.95,
      maxTokens: 3000,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`OpenAI API error (${response.status}): ${errorText}`);
  }

  const data = await response.json();
  if (!data.content) {
    throw new Error('Invalid response format from OpenAI');
  }

  return data.content;
}

/**
 * Execute request with automatic provider failover
 */
async function executeWithFailover(userPrompt: string): Promise<string> {
  console.log(`üîÑ Generating Bible Question - Starting provider chain...`);

  // Try OpenAI first (confirmed working)
  try {
    console.log(`üîÑ Trying ${PROVIDERS.OPENAI.name} (${PROVIDERS.OPENAI.model})...`);
    const result = await callOpenAI(userPrompt);
    console.log(`‚úÖ ${PROVIDERS.OPENAI.name} succeeded`);
    return result;
  } catch (error: any) {
    console.warn(`‚ö†Ô∏è ${PROVIDERS.OPENAI.name} failed:`, error.message);
  }

  // Fallback to Ollama Cloud
  try {
    console.log(`‚Ü™Ô∏è Falling back to ${PROVIDERS.OLLAMA.name} (${PROVIDERS.OLLAMA.model})...`);
    const result = await callOllamaCloud(userPrompt);
    console.log(`‚úÖ ${PROVIDERS.OLLAMA.name} succeeded`);
    return result;
  } catch (error: any) {
    console.warn(`‚ö†Ô∏è ${PROVIDERS.OLLAMA.name} failed:`, error.message);
  }

  // Final fallback to Gemini
  try {
    console.log(`‚Ü™Ô∏è Falling back to ${PROVIDERS.GEMINI.name} (${PROVIDERS.GEMINI.model})...`);
    const result = await callGemini(userPrompt);
    console.log(`‚úÖ ${PROVIDERS.GEMINI.name} succeeded`);
    return result;
  } catch (error: any) {
    console.error(`‚ùå ${PROVIDERS.GEMINI.name} failed:`, error.message);
  }

  throw new Error('All AI providers failed. Please check your configuration and try again.');
}

/**
 * Parse JSON response (handles markdown code blocks from some providers)
 */
function parseJSONResponse(text: string): any {
  // Remove markdown code blocks if present
  let cleanedText = text.trim();

  if (cleanedText.startsWith('```json')) {
    cleanedText = cleanedText.replace(/^```json\s*/, '').replace(/```\s*$/, '');
  } else if (cleanedText.startsWith('```')) {
    cleanedText = cleanedText.replace(/^```\s*/, '').replace(/```\s*$/, '');
  }

  return JSON.parse(cleanedText.trim());
}

/**
 * Generate a biblical question with automatic provider failover
 */
export const generateBiblicalQuestion = async (
  userPrompt: string
): Promise<Omit<Quest, 'id' | 'characterImage'>> => {
  const resultText = await executeWithFailover(userPrompt);
  const parsedResponse = parseJSONResponse(resultText);

  // Randomize the answer positions to avoid bias
  const { options: randomizedOptions, correctAnswerIndex: randomizedIndex } = randomizeAnswers(
    parsedResponse.options,
    parsedResponse.correctAnswerIndex
  );

  // Transform the response into Quest format
  const quest: Omit<Quest, 'id' | 'characterImage'> = {
    character: parsedResponse.character,
    category: parsedResponse.category as QuestionCategory,
    question: parsedResponse.question,
    options: randomizedOptions,
    correctAnswerIndex: randomizedIndex,
    explanation: parsedResponse.explanation,
    journalPrompt: {
      title: parsedResponse.journalPromptTitle,
      content: parsedResponse.journalPromptContent
    },
    deepDive: {
      title: parsedResponse.deepDiveTitle,
      content: parsedResponse.deepDiveContent,
      sources: parsedResponse.bibleSources.map((source: any) => ({
        text: source.reference,
        url: `https://www.biblegateway.com/passage/?search=${encodeURIComponent(source.englishReference)}&version=NIV`
      }))
    }
  };

  return quest;
};

/**
 * Generate a biblical question with specific topic parameters
 */
export const generateBiblicalQuestionWithTopic = async (
  characterName?: string,
  topic?: string,
  testament?: 'old' | 'new' | 'both'
): Promise<Omit<Quest, 'id' | 'characterImage'>> => {
  let prompt = "Ë´ãÁîüÊàê‰∏ÄÂÄãËÅñÁ∂ìÂïèÈ°å";

  if (characterName) {
    prompt += `ÔºåÈóúÊñºËÅñÁ∂ì‰∫∫Áâ©„Äå${characterName}„Äç`;
  }

  if (topic) {
    prompt += `Ôºå‰∏ªÈ°åÊòØ„Äå${topic}„Äç`;
  }

  if (testament === 'old') {
    prompt += "Ôºå‰æÜËá™ËàäÁ¥ÑËÅñÁ∂ì";
  } else if (testament === 'new') {
    prompt += "Ôºå‰æÜËá™Êñ∞Á¥ÑËÅñÁ∂ì";
  }

  prompt += "„ÄÇ";

  return generateBiblicalQuestion(prompt);
};
